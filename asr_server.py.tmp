# asr_server.py
import asyncio
import websockets
import numpy as np
from reazonspeech.k2.asr import (
    load_model,
    transcribe,
    audio_from_numpy
)

SAMPLE_RATE = 16000
CHUNK_DURATION = 0.5  # ç§’
CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_DURATION)

print("ğŸš€ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
model = load_model(device='cpu')

async def recognize(websocket):
    buffer = np.empty((0,), dtype=np.float32)
    print("ğŸ”Œ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š")

    try:
        async for message in websocket:
            chunk = np.frombuffer(message, dtype=np.float32)
            buffer = np.concatenate([buffer, chunk])

            while len(buffer) >= CHUNK_SIZE:
                segment = buffer[:CHUNK_SIZE]
                buffer = buffer[CHUNK_SIZE:]

                audio = audio_from_numpy(segment, SAMPLE_RATE)
                result = transcribe(model, audio)
                print(f"ğŸ“ {result.text}")
                await websocket.send(result.text)

    except websockets.exceptions.ConnectionClosed:
        print("ğŸ”Œ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ‡æ–­")

async def main():
    print("ğŸ“¡ WebSocket ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­ (port=8000)")
    async with websockets.serve(recognize, "0.0.0.0", 8000):
        await asyncio.Future()  # ç„¡é™ãƒ«ãƒ¼ãƒ—

if __name__ == "__main__":
    asyncio.run(main())

